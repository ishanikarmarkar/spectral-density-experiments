{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9e1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import primerange\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from scipy.stats import wasserstein_distance as w1_dist\n",
    "import scipy as sp\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from scipy.sparse import eye, csr_matrix\n",
    "import spectral_density as spec\n",
    "import ot\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8acac7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Copied from Apoorv's implementation with a few modifications to make matrices scipy sparse '''\n",
    "\n",
    "def eig_normAdj(G):\n",
    "    #Returns normalized adjacency eigenvalues\n",
    "    return np.ones(nx.number_of_nodes(G)) - nx.normalized_laplacian_spectrum(G).real\n",
    "\n",
    "# def get_normAdj(G):\n",
    "#     # Returns the normalized adjacency matrix\n",
    "#     return np.eye(G.number_of_nodes()) - nx.normalized_laplacian_matrix(G).toarray()\n",
    "\n",
    "def get_normAdj(G):\n",
    "    # Calculate the normalized Laplacian matrix (already in sparse format)\n",
    "    norm_laplacian = nx.normalized_laplacian_matrix(G)\n",
    "    # Identity matrix in sparse format, directly created as sparse for efficiency\n",
    "    I = eye(G.number_of_nodes(), format='csr')\n",
    "    # Subtract the normalized Laplacian matrix from the identity matrix\n",
    "    sparse_norm_adj_matrix = I - norm_laplacian\n",
    "    return sparse_norm_adj_matrix\n",
    "\n",
    "def find_vtx_index(vtx_u, vtx_v, adj_list_G):\n",
    "    # Finds the index of vtx_v in the adjacency list of vtx_u\n",
    "    for idx in range(len(adj_list_G[vtx_u])):\n",
    "        if adj_list_G[vtx_u][idx] == vtx_v:\n",
    "            return idx\n",
    "        \n",
    "def replacement_prod(G,l):\n",
    "    adj_list_G = {}\n",
    "    # Create a dictionary of neighbour lists\n",
    "    for vtx in G.nodes():\n",
    "        neighbour_list = list(G.neighbors(vtx))\n",
    "        adj_list_G[vtx] = neighbour_list\n",
    "    # G_rep: Initialize the replacement product graph\n",
    "    G_rep = nx.Graph()\n",
    "    # Create the nodes of the replacement product graph \n",
    "    # Indexed by the original vertex and the index of the neighbour\n",
    "    for vtx in G.nodes():\n",
    "        for j in range(l):\n",
    "            G_rep.add_node((vtx,j))\n",
    "    # Create the edges of the replacement product graph from the original graph G\n",
    "    for vtx in G.nodes():\n",
    "        for j in range(l):\n",
    "            j_th_neighbour = adj_list_G[vtx][j]\n",
    "            idx_of_vtx = find_vtx_index(j_th_neighbour, vtx, adj_list_G)\n",
    "            G_rep.add_edge((vtx,j),(j_th_neighbour,idx_of_vtx))\n",
    "    # Create the edges to the cycle of the replacement product graph\n",
    "    for vtx in G.nodes():\n",
    "        for j in range(l):\n",
    "            if j == l-1:\n",
    "                k = 0\n",
    "                G_rep.add_edge((vtx,j),(vtx,k))\n",
    "            else:\n",
    "                G_rep.add_edge((vtx,j),(vtx,j+1))\n",
    "    return G_rep\n",
    "\n",
    "\n",
    "def compute_tridiag(A, k, m=3):\n",
    "    # run Lanczos and get recurrence coefficients\n",
    "    αβ_list = []\n",
    "    d = A.shape[0]\n",
    "    for _ in range(m):\n",
    "        # generate random vector\n",
    "        v = np.random.randn(d)\n",
    "        v /= np.linalg.norm(v)\n",
    "        # run Lanczos and append coefficients\n",
    "        αβ_list.append(spec.lanczos(A,v,k,reorth=False))\n",
    "    return αβ_list\n",
    "\n",
    "def compute_w(f_x, g_x, x): \n",
    "    # Normalize histograms\n",
    "    f_x /= np.sum(f_x)\n",
    "    g_x /= np.sum(g_x)\n",
    "    # Define the ground metric\n",
    "    M = np.abs(x[:, np.newaxis] - x[np.newaxis, :])\n",
    "    wasserstein_dist = ot.emd2(f_x, g_x, M)\n",
    "    return wasserstein_dist\n",
    "\n",
    "def compute_distance():\n",
    "    l = []\n",
    "    for i in range(5,15,2):\n",
    "        l.append(i)\n",
    "    w1_lst = []\n",
    "    for i in tqdm(l, desc='Iterating over ls'):\n",
    "        \n",
    "        print(\"Starting l = \" , str(i))\n",
    "        \n",
    "        # Determine size of graph and target error (set to be like 1/l^3)\n",
    "        n = int(np.ceil(np.log(i) * 2 ** i))\n",
    "        if n % 2 == 1:\n",
    "            n = n + 1\n",
    "        error = 1/(2*i**3)\n",
    "        \n",
    "        # set N in KPM according to the target error (set accoridng to Tyler's paper)\n",
    "        N = int(np.ceil(36/error))\n",
    "        \n",
    "        print(\"\\t generating graphs... \")\n",
    "        G2 = nx.random_regular_graph(2*i,n)\n",
    "        G2_r = replacement_prod(G2, 2*i)\n",
    "        AG2_r = get_normAdj(G2_r)\n",
    "        \n",
    "        G1 = nx.random_regular_graph(i,n)\n",
    "        G1_r = replacement_prod(G1, i)\n",
    "        AG1_r = get_normAdj(G1_r)\n",
    "        \n",
    "        # number of LDOS to average (set according to Tyler's suggestion)\n",
    "        m = 10\n",
    "        \n",
    "        print(\"Matrix shape is\", AG1_r.shape)\n",
    "        print(\"\\t running first lanczos... \")\n",
    "        start_time = time.time()\n",
    "        αβ_list1 = compute_tridiag(AG1_r, int(np.ceil(N/2)), m=m)\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            \"\\t\\t completed in \", \n",
    "            str(end_time-start_time), \n",
    "            \" seconds, i.e. \", \n",
    "            str((end_time-start_time)/int(np.ceil(N/2))), \n",
    "            \" seconds per iteration.\"\n",
    "        )\n",
    "        \n",
    "#         print(\"\\t computing first density... \")\n",
    "#         σ1 = spec.get_arcsin_density(-1,1, N)\n",
    "#         ρ_KPM1 = spec.KPM(αβ_list1,σ1)\n",
    "        \n",
    "#         print(\"\\t running second lanczos... \")\n",
    "#         start_time = time.time()\n",
    "#         αβ_list2 = compute_tridiag(AG2_r, int(np.ceil(N/2)), m=m)\n",
    "#         end_time = time.time()\n",
    "#         print(\n",
    "#             \"\\t\\t completed in \", \n",
    "#             str(end_time-start_time), \n",
    "#             \" seconds, i.e. \", \n",
    "#             str((end_time-start_time)/int(np.ceil(N/2))), \n",
    "#             \" seconds per iteration.\"\n",
    "#         )\n",
    "#         print(\"\\t computing second density... \")\n",
    "#         σ2 = spec.get_arcsin_density(-1,1, N)\n",
    "#         ρ_KPM2 = spec.KPM(αβ_list2,σ2)\n",
    "        \n",
    "        \n",
    "#         print(\"\\t computing w1 distance... \")\n",
    "#         x = np.linspace(-1,1, 20000)\n",
    "#         y1 = ρ_KPM1(x,damping='Jackson')\n",
    "#         y2 = ρ_KPM2(x,damping='Jackson')\n",
    "        \n",
    "#         w1 = compute_w(y2, y1, x)\n",
    "#         w1_lst.append(w1)\n",
    "        \n",
    "#         print(\"\\t Completed l = \", str(i), \" and W1 distance is \", str(w1))\n",
    "    return w1_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237990e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d448bb04d54f18aeb5703e12a824e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterating over ls:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting l =  5\n",
      "\t generating graphs... \n",
      "Matrix shape is (260, 260)\n",
      "\t running first lanczos... \n",
      "\t\t completed in  0.8709361553192139  seconds, i.e.  0.0001935413678487142  seconds per iteration.\n",
      "Starting l =  7\n",
      "\t generating graphs... \n",
      "Matrix shape is (1750, 1750)\n",
      "\t running first lanczos... \n",
      "\t\t completed in  4.317597150802612  seconds, i.e.  0.00034965963320396923  seconds per iteration.\n",
      "Starting l =  9\n",
      "\t generating graphs... \n",
      "Matrix shape is (10134, 10134)\n",
      "\t running first lanczos... \n",
      "\t\t completed in  34.213019132614136  seconds, i.e.  0.001303601414845271  seconds per iteration.\n",
      "Starting l =  11\n",
      "\t generating graphs... \n",
      "Matrix shape is (54032, 54032)\n",
      "\t running first lanczos... \n",
      "\t\t completed in  292.2389569282532  seconds, i.e.  0.006098984826117647  seconds per iteration.\n",
      "Starting l =  13\n",
      "\t generating graphs... \n",
      "Matrix shape is (273182, 273182)\n",
      "\t running first lanczos... \n",
      "\t\t completed in  2942.208472967148  seconds, i.e.  0.03719982391350766  seconds per iteration.\n"
     ]
    }
   ],
   "source": [
    "w1_lst = compute_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fdecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectral-density)",
   "language": "python",
   "name": "spectral-density"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
